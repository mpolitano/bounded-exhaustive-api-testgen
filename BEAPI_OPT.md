# Assessing the impact of `BEAPI`'s optimizations (RQ2 in Section 4.2 of the paper)

In this section, we assess the impact of `BEAPI`'s optimizations in its performance. We provide four different ways to execute `BEAPI`: DEFAULT (SM/BLD in the paper) is `BEAPI` with state matching enabled (SM) and using identified builders (BLD); SM is `BEAPI` with only state matching (SM) enabled; BLD is `BEAPI` using identified builders (BLD); and NoOpt is `BEAPI` with both optimizations disabled. 

## Running a single experiment

To generate inputs using `BEAPI` with a given configuration run the following script:

```
./run-testgen-beapi-optimizations.sh <benchmark> <case study> <scope> <config>
```

where `<benchmark>` is one of `0_korat`, `1_kiasan`, `2_roops`, `3_fajita`, `4_real_world`; `<case study>` is one of the case studies of `<benchmark>` (see below for the available cases for each benchmark); `<scope>` is the maximum number of nodes and the number of integers (from 0 to scope-1) available for generation, and `<config>` is one of the four aformentioned `BEAPI` configurations: `DEFAULT`, `SM`, `BLD`, `NoOpt`.

For example, to generate inputs for `SinglyLinkedList` from the `0_korat` benchmark using `BEAPI`'s DEFAULT configuration with a scope of `4` execute: 
```
./run-testgen-beapi-optimizations.sh 0_korat korat.examples.singlylinkedlist.SinglyLinkedList 4 DEFAULT

```

The  **tests suite** generated by `BEAPI` is stored in the `beapi-tests` folder, located inside the specified project. For the example given above, the tests are stored in `korat_0/beapi-tests`. 


The screen shows a summary of the results obtained, as well as the path to the log file that `BEAPI` throws as output when running on the specified configuration. Also, the results are stored, in a more readable way, as a CSV format file (```results_optimizations.csv```) located in ```script/results-optimizations``` folder.  


The information tabulated in the CSV file correspond to:

- Case study information: **Project** benchmark and case study **Class**
- Running **Technique** Configuration (See below for a description)
- **Budget** (scope) used for input generation
- **Time** spent for input generation (In milliseconds)
- Number of **Structures** generated
- Number of structures visited (**Explored**) during generation
 
Regarding **Technique Configurations**, the description corresponds to:

- `beapi/matching/builders` &rarr;  `DEFAULT` configuration
- `beapi/matching/no-builders` &rarr;  `SM` configuration  
- `beapi/no-matching/builders` &rarr;  `BLD` configuration
- `beapi/no-matching/no-builders` &rarr;  `NoOpt` configuration 

The data stored in this CSV file corresponds to that displayed in **Table 2** of **Section 4.2** of the paper. This paper table only shows, for certain scopes (**s**), the times spent on generation for each configuration, for the case studies mentioned in the section below. It is important to note that the times in the paper table are shown in seconds, while in the CSV report they are displayed in milliseconds.  Furthermore, when the CSV report does not show data for a certain case study, it means that  the time limit has been  exceeded (timeout set to 1 hour). 

Note: The precomputed builder methods used to run the experiments reported in **Table 2** of **Section 4.2** of the paper, when `DEFAULT` and `BLD` configurations are used, are stored in `scripts/config/<benchmark>/builder/<case study>` file,  for each `<benchmark>` and `<case study>`.

## Available case studies

- `0_korat`
  - `DoublyLinkedList`: korat.examples.doublylinkedlist.DoublyLinkedList (`DDList`)
  - `FibonacciHeap`: korat.examples.fibheap.FibonacciHeap (`FibHeap`)
  -	`BinomialHeap`: korat.examples.binheap.BinomialHeap (`BinHeap`)
  - `SearchTree`:korat.examples.searchtree.SearchTree (`BST`)
  - `SinglyLinkedList`: korat.examples.singlylinkedlist.SinglyLinkedList (`SLList`)
  - `RedBlackTree`: korat.examples.redblacktree.RedBlackTree (`RBT`)
  - `SortedList`: korat.examples.sortedlist.SortedList (`SortedList`) 

- `1_kiasan`
  - `BinarySearchTree`: binarysearchtree.BinarySearchTree (`BST`)
  - `DoubleLinkedList`: doublylinkedlist.DoubleLinkedList (`DDL`)
  - `TreeSet`: redblacktree.TreeSet(`RBT`) UBICAR LOS FUENTES DONDE CORRESPONDE con el nombre correcto
  - `DisjSetsFast`: disjointSet.fast.DisjSetsFast (`DisjSetFast`)
  - `StackLi`: stack.list.StackLi (`StackList`)
  - `BinaryHeap`: binaryheap.BinaryHeap (`BHeap`)
  - `TreeMap`: redblacktree.TreeMap (`TreeMap`)
  - `DisjSet`: disjointSet.orig.DisjSets (`DisjSet`) 
  - `StackAr`: stack.array.StackAr (`StackAr`)

- `2_roops`

  - `AvlTree`: avl.AvlTree (`AVL`)
  - `NodeCachingLinkedList`: ncl.NodeCachingLinkedList (`NCL`)
  - `BinTree`: bintree.BinTree (`BinTree`)
  - `LinkedList`: linkedlist.LinkedList (`LList`)
  - `TreeSet`: rbt.TreeSet (`RBT`)
  - `FibHeap`: fibheap.FibHeap (`FibHeap`)
  - `BinomialHeap`: bheap.BinomialHeap (`BinHeap`)


- `3_fajita`
  - `BinTree`: bintree1.BinTree (`BinTree`)
  - `AvlTree`: avl1.AvlTree (`AVL`)
  - `TreeSet`: rbt.TreeSet (`RBT`)
  - `BinomialHeap`: bheap.BinomialHeap (`BinHeap`)
  - `SinglyLinkedList`: list.SinglyLinkedList (`SLList`) 
  - `DoubleLinkedList`: cdlist.LinkedList (`DLList`)
  - `NodeCachingLinkedList`: cList.NodeCachingLinkedList (`NCL`)

- `4_real_world`
 
  - `NodeCachingLinkedList `: org.apache.commons.collections4.list.NodeCachingLinkedList (`NCL`)
  - `TreeSet`: java2.util2.treeset.TreeSet (`TSet`)
  - `TreeMap`: java2.util2.treemap.TreeMap (`TMap`)
  - `LinkedList`: java2.util2.linkedlist.LinkedList (`LList`)
  - `HashMap`: java2.util2.hashmap.HashMap (`HMap`)
  - `Schedule`: builders.Schedule (`Schedule`)  


Note: The text that is inside parentheses in each case, corresponds to the short names used in **Table 2** of **Section 4.2** of the paper, to identify each case study. For space reasons, the aforementioned paper table shows only results from the `2_roops` and `4_real-world` benchmarks, while the others were included in the replication package that accompanies the paper.

## Running all experiments from a single benchmark (slow)

To reproduce all the experiments for a specific benchmark using all of `BEAPI` configurations, for all scopes within XXX and YYY COMPLETAR! pick and run one of following commands: 

```
./run-testgen-beapi-optimizations-0_korat.sh
./run-testgen-beapi-optimizations-1_kiasan.sh
./run-testgen-beapi-optimizations-2_roops.sh
./run-testgen-beapi-optimizations-3_fajita.sh
./run-testgen-beapi-optimizations-real-world.sh
```

Note: Running one of the above scripts might take a day or longer depending on your hardware

## Running all the experiments (very slow)

To reproduce all the experiments for this research question run:
```
./run-testgen-beapi-optimizations-all.sh
```

Note: Running this script might take a few days or longer depending on your hardware


# Running automated builders identification (Last paragraph of Section 4.2)

HAY QUE DECIR QUE ESTO ES DE OTRO PAPER.

In this section, we assess the cost of builder identification. For space reasons the result of builder identification are not show in the paper but on the paper website.

## Running a single experiment

To identify builders methods for a given  case study, run the following script:

```
./run-builder-identification.sh <benchmark> <case study>
```
where `<benchmark>` is one of `0_korat`, `1_kiasan`, `2_roops`, `3_fajita`, `4_real_world`; and `<case study>` is one of the case studies of `<benchmark>` ( case studies are the same as the available case studies listed on previous  section ([Available case studies](#available-case-studies))

For example, to identify builders methods  for `SinglyLinkedList` from the `0_korat` benchmark, execute: 

```
./run-builder-identification.sh 0_korat korat.examples.singlylinkedlist.SinglyLinkedList

```

The screen shows a summary of the results obtained, as well as the path to the log file that builder computation throws as output. Also, the results are stored, in a more readable way, as a CSV format file (```results_builders.csv```) located in ```script/results-builders``` folder.  


The information tabulated in the CSV file correspond to:

- Case study information: **case study**
- Identified builder methods (**builders**)
- **Time** spent for builder identification process (In seconds)
- Number of total public methods declared by the specified case study class

For the example given above, the identified builders methods are the following:

 - Parameterless SinglyLinkedList Constructor: `korat.examples.singlylinkedlist.SinglyLinkedList.<init>()`
 - Method to append a given object to the list: `korat.examples.singlylinkedlist.SinglyLinkedList.add(java.lang.Object)`


## Running all experiments from a single benchmark


To identify builders for all case studies for a specific benchmark, pick and run one of following commands: 

```
./run-builder-identification-0_korat.sh
./run-builder-identification-1_kiasan.sh
./run-builder-identification-2_roops.sh
./run-builder-identification-3_fajita.sh
./run-builder-identification-4-real-world.sh
```


## Running all the experiments 


To identify builders methods  for all [available case studies](#available-case-studies) run:

```
./run-testgen-beapi-optimizations-all.sh
```

